using docker applications can run the same way one every machine 

Docker is an open-source platform that allows you to build, ship, and run applications in containers.
Containers are lightweight, portable, and isolated environments that include everything needed to run an application—code, runtime, libraries, and dependencies.

docker container is a package of code , dependencies , libraries required for your application to run 


Key Features of Docker
Containerization: Packages applications and dependencies together to run consistently across different environments.

Portability: Runs on any system with Docker installed, whether it's a developer’s laptop, a testing server, or a production cloud environment.

Isolation: Each container runs independently, preventing conflicts between applications.

Scalability: Easily scales applications by running multiple containers.

Efficiency: Uses fewer resources than traditional virtual machines (VMs) because containers share the host OS.

Docker shares the kernel of the host machine. Unlike virtual machines (VMs), which include a full guest OS, Docker containers run directly on the host’s OS kernel, making them lightweight and efficient.

If the host machine is Windows-based and you want to run Linux-based containers, Docker does not share the Windows kernel directly with the Linux containers. Instead, it runs a lightweight Linux virtual machine (VM) in the background to provide a Linux kernel.


========================
How Docker Works
========================
Docker file: Defines how to build an image (like a blueprint).

Docker Image: A snapshot of an application with its dependencies.

Docker Container: A running instance of an image.

Docker Hub: A repository for sharing and storing Docker images.
==================================================
CREATING AND USING DOCKER CONTAINERS		||
==================================================

docker container run --pulish 80:80 nginx = launch nginx server that can be accessed through localhost this command runs the container in the foreground with the logs 

docker container run --publish 80:80 --detach nginx = launch nginx server in the background 

docker container run --publish 80:80 --name containername nginx = launch nginx server and give container a name 
docker container ls = list all the running conatiners 

docker contianer ls -a = list all the containers running and stopped 

=================================================		
DOCKER NETWORKS					||
==================================================		

docker container run -p = -p exposes the port on your machine 
each docker container is connected to a private virtual network "bridge" by defalut the containers connected to the newtork is called bridge 
all containers connected to the virtual network can talk to eachother without -p
Publishing the ports are always in host:container format  example : -p 80:80 nginx 
==================================================
COMMANDS 					||
==================================================
docker container port containername = displays the ports open for the container 
docker newtwork ls = displays all the network devices are connected to 

docker network inspect network name (exmple host,bridge etc) = displays the containers connected to the network and other info in a json format 

docker container inspect = details about the contianers in json format 

docker network connect networkname container name = connects the container to specified network 


==========================================================================
Types Docker networks							||
==========================================================================
1) BRIDGE (DEFAULT)
Used by default when running a container without specifying a network.
Allows containers to communicate only if they are on the same bridge network.
The host cannot directly access containers.

example:docker network create my-bridge-network
docker run -d --name app1 --network my-bridge-network nginx
docker run -d --name app2 --network my-bridge-network alpine ping app1


2) HOST 
it gains performance by skipping virtual network but sacrifices the security of the container model 
the container on the host network are directly attached to the host interface 

Removes network isolation—container shares the host’s IP.

example:docker run --rm --network host nginx


3) NONE
Completely isolates the container from networking.
Useful for security or debugging purposes.
The container cannot connect to other containers, the host, or the internet.

example :docker run --rm --network none nginx


==========================================================================
DOCKER DNS								||
==========================================================================
CANNOT RELY ON DOCKERS IP ADDRESS TO COMMUNICATE WITH EACH OTHER 
-----------------------------------------------------------------
a docker containers ip address is not static by default (we can make it static by using docker compose command ) the ip might change after stopping and running the container backup 
so we cannot relay on the ip address of the container insted we can use container name as the dns name because the container name is unique and it will be easeier to remember 

docker container run --network <network_name> --network-alias <alias_name> <image> = gives alias to a docker container that works as the dns 


=======================================================================================================================================================================================
==========================================================================
DOCKER IMAGE								||
==========================================================================
What is an image 
	App bineries and dependencies 
	metadata about the image data and how to run the image 

docker image ls = list all the images you have used 

	docker pull imagename=pull an image from docker hub 
	docker image push = uploads changed layers to a image registry (docker hub default)
image tags are labels that point to the image id
image tags can be anything but it must specify the version or somthing meaningfull
the default tag is latest but the latest tag should be given to the latest stable version of the image 
image tags example :- latest(default) ,11.1.1 , mainframe

		docker image tag sourceimage tag targetimage tag = how to retag an image 
===========================================================================
IMAGE LAYERS 								||
===========================================================================

Docker uses a layered filesystem to optimize storage and build efficiency. Each instruction in a Dockerfile creates a new layer, which is cached and reused to speed up builds.

In Docker, an image is built using multiple layers. These layers help save storage, improve efficiency, and speed up builds

Each Docker image consists of stacked, read-only layers.
A layer is created when you add a command in a Dockerfile (like RUN, COPY, or ADD).
Layer Caching: How Docker Speeds Up Builds
If you rebuild the image and only modify COPY app.py, Docker will reuse all previous layers except the modified one.


===========================================
Layer Caching: How Docker Speeds Up Builds||
===========================================
Docker caches unchanged layers to speed up builds.
If a command doesn’t change, Docker reuses the previous layer.
If a layer changes, all layers below it must be rebuilt.

docker image inspect imagename = retuns json metadata about the image 
 

==========================================
CREATING IMAGE USING DOCKERFILE		||
==========================================


docker image build -t nginx-with-html . = build an image using docker file (.) in end represents 

docker container run -p 80:80 -rm nginx-with-html = create a container with custom image 

you can name a Dockerfile anything you want, but the default name is Dockerfile (without any extension). If you name it something else, you must specify the filename when building the image using the -f flag. For example:

docker build -t my-image -f MyCustomDockerfile .

=========================================
EXAMPLE DOCKERFILE			||
=========================================
FROM openjdk:21-jdk			||------------------> base image

WORKDIR /javaapp			||------------------> working directory where every process will happen 

EXPOSE 8080				||------------------> exposing the port where people can connect to 

COPY HelloWorld.java HelloWorld.java	|| -----------------> copy the code from local to the image

RUN javac HelloWorld.java		||------------------> compile the code 

CMD ["java" , "HelloWorld.java"] 	||------------------> there can only be one command per container 

=========================================

========================================================================================================================================================================================

==========================================
DOCKER VOLUME				||
==========================================
A Docker Volume is a persistent storage mechanism that allows data to be stored outside the container's filesystem. Volumes help in data persistence, even if the container is stopped or removed.

Why Use Docker Volumes?
***********************
Persist Data → Prevents data loss when containers restart.
Share Data → Multiple containers can access the same volume
Easier Backup & Migration – Volumes can be backed up and moved between environments.

docker volume create volumename

sudo docker run -it -v volumename:/dirloc --name my-container-01 ubuntu

UNMOUNTING IS NOT POSSIBLE YOU HAVE TO DELETE THE CONTAINER AND RECREATE IT 


To mount a volume with the docker run command, you can use either the --mount or --volume flag.


 docker run --mount type=volume,src=<volume-name>,dst=<mount-path>
 docker run --volume <volume-name>:<mount-path>
In general, --mount is preferred. The main difference is that the --mount flag is more explicit and supports all the available options.

You must use --mount if you want to:

Specify volume driver options	
Mount a volume subdirectory


=========================
Docker in Docker (DinD)
=========================

Docker in Docker (DinD) refers to running a Docker daemon inside a Docker container. This setup allows you to build, run, and manage containers inside another container.

Why Use Docker in Docker?

CI/CD Pipelines → Used in tools like GitLab CI, Jenkins, and GitHub Actions for building and testing Docker images.

Containerized Development → Allows users to run Docker commands inside isolated environments.

Sandboxing → Provides an isolated environment to test Docker features.

Multi-Tenant Environments → Each user gets their own Docker daemon.





docker installation ubuntu :-

# Add Docker's official GPG key:
sudo apt-get update
sudo apt-get install ca-certificates curl
sudo install -m 0755 -d /etc/apt/keyrings
sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
sudo chmod a+r /etc/apt/keyrings/docker.asc

# Add the repository to Apt sources:
echo"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu $(. /etc/os-release && echo "${UBUNTU_CODENAME:-$VERSION_CODENAME}") stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/nullsudo apt-get update





.dockerignore= use these files to ignore the file you dont want from your project to be copied while building docker image 

		